---
title: "Statistical Linear Modeling for Hourly PM2.5 Multi-Step Time Series Forecasting in San Francisco"
subtitle: "Eleanor Kim"
date: '2024-04-12'
output:
  pdf_document: default
  html_document: default
---

# Set Up

```{r, warning = FALSE}
# Load libraries
library(dplyr)
library(car)
library(lubridate)
library(sandwich)
library(lmtest)
library(ggplot2)
library(glmnet)
library(MASS)
library(knitr)
```

# Data Cleaning

```{r}
# Read data
d = read.csv("sf_pollution.csv")
```

```{r}
# Remove index column
d2 = d[,-c(1)]

# Data must have a Device_Name
d3 = filter(d2, !is.na(Device_Name))

# Pm2.5 should not be negative
d4 = filter(d3, PM2.5_Hour_MassConc_Calibrated >= 0)

# Data must belong to one of the 5 neighborhoods with active PM2.5
data <- d4 %>%
  filter(Neighborhood %in% c("BVHP", "Chinatown", "Potrero Hill", "SoMa", "Tenderloin"))
```

```{r}
# Convert 'Datetime' column to POSIXct format
data$Datetime <- as.POSIXct(data$Datetime)

# Convert Datetime to month
data$Month <- format(data$Datetime, "%m")

# Convert month to numeric
data$Month <- as.numeric(data$Month)

# Define a function to convert month to season
get_season <- function(month) {
  if (month %in% c(3, 4, 5)) {
    return("Spring")
  } else if (month %in% c(6, 7, 8)) {
    return("Summer")
  } else if (month %in% c(9, 10, 11)) {
    return("Fall")
  } else {
    return("Winter")
  }
}

# Apply the function to create the 'Season' variable
data$Season <- sapply(data$Month, get_season)

# Remove the 'Month' column
data$Month <- NULL
```

```{r}
# Inspect data
nrow(data) # 546743 observations
names(data) 
# "ID", "Datetime","PM1_Hour_MassConc_Raw","PM2.5_Hour_MassConc_Calibrated",       
# "PM10_Hour_MassConc_Raw" , "NO2_Hour_MassConc_Calibrated", "NO2_Hour_MassConc_Raw",
# "Temperature","Humidity", "Latitude","Longitude", "Device_Name", "Neighborhood","Season"
d_drop <- data[,-c(3,5,6,7)]
str(d_drop)
summary(data$PM2.5_Hour_MassConc_Calibrated ,na.rm=TRUE)
```

# Exploratory Data Analysis

```{r}
# Outliers in PM2.5
# Histogram
ggplot(data, aes(x = PM2.5_Hour_MassConc_Calibrated)) +
  geom_histogram(binwidth = 1, fill = "skyblue") +
  labs(title = "Histogram of PM2.5 Levels")
ggplot(data, aes(y = PM2.5_Hour_MassConc_Calibrated)) +
  geom_boxplot(fill = "skyblue", width = 0.5) +
  coord_flip() +  # Flip the coordinates to make it sideways
  labs(title = "Box Plot of PM2.5 Levels", y = "PM2.5 Levels")

# Seasonal effects on PM2.5
# Time series plot
ggplot(data, aes(x = Datetime, y = PM2.5_Hour_MassConc_Calibrated, color = Season)) +
  geom_line(size = .1) +
  labs(title = "PM2.5 Levels Over Time by Season")
```


```{r}
# Neighborhood effects on PM2.5
# Create overlapping histograms for PM2.5 levels in each neighborhood
ggplot(data, aes(x = PM2.5_Hour_MassConc_Calibrated, fill = Neighborhood)) +
  geom_histogram(binwidth = 1, position = "identity", alpha = 0.5) +
  labs(title = "Histogram of PM2.5 Levels by Neighborhood", x = "PM2.5 Levels") +
  scale_fill_brewer(palette = "Set1") +  # Set color palette for neighborhoods
  theme_minimal()
# Create separate histograms for PM2.5 levels in each neighborhood
ggplot(data, aes(x = PM2.5_Hour_MassConc_Calibrated, fill = Neighborhood)) +
  geom_histogram(binwidth = 1, position = "identity") +
  labs(title = "Histogram of PM2.5 Levels by Neighborhood", x = "PM2.5 Levels") +
  facet_wrap(~ Neighborhood, scales = "free")
```


```{r}
# Humidity vs PM2.5
# Scatter plot
ggplot(data, aes(x = Humidity, y = PM2.5_Hour_MassConc_Calibrated)) +
  geom_point(size = .5, alpha = 0.1) +
  labs(title = "Scatter Plot of PM2.5 vs. Humidity")

# Temperature vs PM2.5
# Scatter plot
ggplot(data, aes(x = Temperature, y = PM2.5_Hour_MassConc_Calibrated)) +
  geom_point(size = .5, alpha = 0.1) +
  labs(title = "Scatter Plot of PM2.5 vs. Temperature")

# Correlation analysis
correlationt <- cor(data$Temperature, data$PM2.5_Hour_MassConc_Calibrated)

```

```{r}
# Calculate the correlation between Humidity and PM2.5
correlation <- cor(data$Humidity, data$PM2.5_Hour_MassConc_Calibrated)

# Perform a hypothesis test for correlation
cor_test <- cor.test(data$Humidity, data$PM2.5_Hour_MassConc_Calibrated)

# Print the correlation coefficient and p-value
print(correlation)
print(cor_test)

# Calculate the correlation between Temperature and PM2.5
correlation <- cor(data$Temperature, data$PM2.5_Hour_MassConc_Calibrated)

# Perform a hypothesis test for correlation
cor_test <- cor.test(data$Temperature, data$PM2.5_Hour_MassConc_Calibrated)

# Print the correlation coefficient and p-value
print(correlation)
print(cor_test)

```

# Feature Engineering & Preprocessing

```{r}
# Function that produces training and testing data with lagged PM2.5 for given number of lag_steps 

generate_lagged_values <- function(lag_steps) {
  lag_data <- data %>%
    arrange(Datetime) %>%
    group_by(Device_Name) %>%
    mutate(
      across(
        starts_with("PM2.5_Hour_MassConc_Calibrated"),
        .fns = setNames(
          lapply(1:lag_steps, function(i) ~lag(., n = i)),
          paste0("lag_", 1:lag_steps)
        ),
        .names = "{.col}_{.fn}"
      )
    ) %>%
    ungroup() %>%
    na.omit()
  train_indices <- sample(1:nrow(lag_data), 0.8 * nrow(lag_data)) # 80% for training
  train_data <- lag_data[train_indices, ]
  test_data <- lag_data[-train_indices, ]
  return(list("lag_data" = lag_data, "train_data" = train_data, "test_data" = test_data))
}
```

## How can we optimize the model's accuracy with respect to the number of lag steps included in the model?

### Model Selection Criteria: MAPE, Adj-R\^2

```{r}
# Set the number of random seeds
num_seeds <- 20  # adjust this as needed

# Define a range of lag steps to test
lag_steps <- 1:10

# Initialize a vector to store optimal lag steps for each seed
optimal_lag_steps <- rep(NA, num_seeds)

# Function to normalize the metrics
normalize <- function(x) {
  mean_x <- mean(x)
  sd_x <- sd(x)
  z_score <- (x - mean_x) / sd_x
  return(z_score)
}

# Loop through different random seeds
for (seed in 1:num_seeds) {
  set.seed(seed)  # Set the random seed
  
  # Initialize vectors to store performance metrics for each lag step
  mape <- rep(NA, length(lag_steps))
  adj_r_squared <- rep(NA, length(lag_steps))
  
  # Loop through different lag steps
  for (i in seq_along(lag_steps)) {
    # Generate training set from lagged data 
    lag_data <- generate_lagged_values(lag_steps[i])$train_data
    
    # Filter lagged variables
    lagged_vars <- grep("^PM2\\.5_Hour_MassConc_Calibrated_lag_", names(lag_data), value = TRUE)
    
    # Train the model
    model <- lm(PM2.5_Hour_MassConc_Calibrated ~ ., data = lag_data[, c("PM2.5_Hour_MassConc_Calibrated", lagged_vars)])
    
    # Evaluate model performance
    predictions <- predict(model, newdata = lag_data)
    actual <- lag_data$PM2.5_Hour_MassConc_Calibrated
    mape[i] <- mean(abs((actual - predictions) / actual)) * 100  # Convert to percentage
    adj_r_squared[i] <- summary(model)$adj.r.squared
  }
  
  # Normalize the metrics
  mape_norm <- normalize(mape)
  adj_r_squared_norm <- normalize(adj_r_squared)
  
  # Calculate the weighted average for each lag step
  weighted_avg <- 0.5 * 1/mape_norm + 0.5 * adj_r_squared_norm
  
  # Find the lag step with the highest weighted average
  optimal_index <- which.max(weighted_avg)
  optimal_lag_steps[seed] <- lag_steps[optimal_index]
}
```

```{r}
# Count the frequency of occurrence of each lag step
lag_step_counts <- table(optimal_lag_steps)

# Find the lag step with the highest frequency
optimal_lag_step <- names(which.max(lag_step_counts))

# Convert optimal_lag_steps to a data frame
optimal_lag_df <- as.data.frame(table(optimal_lag_steps))

# Calculate weights based on frequency
optimal_lag_df$weights <- optimal_lag_df$Freq / sum(optimal_lag_df$Freq)

# Calculate the weighted average
weighted_avg_lag_step <- sum(optimal_lag_df$weights * as.numeric(as.character(optimal_lag_df$optimal_lag_steps)))

# Output the weighted average lag step
optimal_lag_step <- floor(weighted_avg_lag_step)
cat("The optimal number of lag steps to include in the model is",optimal_lag_step)
```

### Generate Training Model (OLS)

```{r}
# Generate data with optimal number of lagged steps
train_data = generate_lagged_values(optimal_lag_step)$train_data

# Filter lagged variables
lagged_vars_train <- grep("^PM2\\.5_Hour_MassConc_Calibrated_lag_", names(train_data), value = TRUE)

# Model Training
ols_model_lag <- lm(PM2.5_Hour_MassConc_Calibrated ~ ., data = train_data[, c("PM2.5_Hour_MassConc_Calibrated",lagged_vars_train)])
summary(ols_model_lag)
```

### Test Model on Performance Criteria: MAPE, Adj-R\^2

```{r}
# Extract test data set
test_data <- generate_lagged_values(optimal_lag_step)$test_data

# Filter lagged variables
lagged_vars_test <- grep("^PM2\\.5_Hour_MassConc_Calibrated_lag_", names(test_data), value = TRUE)

# Make predictions on the test data set
predictions <- predict(ols_model_lag, newdata = test_data[, c("PM2.5_Hour_MassConc_Calibrated", lagged_vars_test)])

# Assess performance using MAPE
MAPE <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100

# Assess performance using Adjusted R-squared
adjusted_r_squared <- summary(ols_model_lag)$adj.r.squared

## Asses performance using AIC
aic <- AIC(ols_model_lag)

# Print the evaluation metrics
cat("MAPE: ", MAPE, "% indicates the average deviation of actual values from the model's predictions\n",sep="")
cat("Adjusted R-squared:", adjusted_r_squared, "indicates the proportion of variability in the dependent variable explained by the independent variables in the model", "\n")
cat("AIC:",aic)

## (Overall, the model seems to have a relatively good fit, as indicated by the high Adjusted R-squared value and the relatively low MAPE.)
```

```{r}
# plot real vs predicted 
plot(test_data$PM2.5_Hour_MassConc_Calibrated, predictions)

## There are definitely outliers in the model from very high values
```

## What are the individual contributions of Humidity, Temperature, Seasonality, and Neighborhood?

### What are the individual contributions of Neighborhood to the model?

#### Full Regression Model (OLS)

```{r}
# Model Training with Neighborhood Variable
ols_model_neighborhood <- lm(PM2.5_Hour_MassConc_Calibrated ~ ., data = train_data[, c("PM2.5_Hour_MassConc_Calibrated", lagged_vars_train, "Neighborhood")])
summary(ols_model_neighborhood)
```

```{r}
# Evaluate model performance

predictions <- predict(ols_model_neighborhood, newdata = test_data)
mape_neigh <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100
adj_rsquared_neigh <- summary(ols_model_neighborhood)$adj.r.squared
aic_neigh <- AIC(ols_model_neighborhood)

# Print the evaluation metrics
cat("MAPE: ", mape_neigh, "% indicates the average deviation of actual values from the model's predictions\n",sep="")
cat("Adjusted R-squared:", adj_rsquared_neigh, "indicates the proportion of variability in the dependent variable explained by the independent variables in the model", "\n")
cat("AIC:", aic_neigh)
```

#### Partial Regression Analysis (FWL)

```{r}
# Extract lagged variables from the training data
lagged_vars <- grep("^PM2\\.5_Hour_MassConc_Calibrated_lag_", names(train_data), value = TRUE)


# Remove NAs from lagged variables
train_data_no_na <- na.omit(train_data[, c("PM2.5_Hour_MassConc_Calibrated", lagged_vars, "Neighborhood")])

# Create dummy variables for the neighborhoods
neighborhood_dummies <- model.matrix(~ Neighborhood - 1, data = train_data_no_na)

# Move the first column to the end
neighborhood_dummies <- cbind(neighborhood_dummies[, -1], neighborhood_dummies[, 1])

# Combine lagged variables and neighborhood dummies
model_data <- cbind(train_data_no_na$PM2.5_Hour_MassConc_Calibrated, train_data_no_na[, lagged_vars], neighborhood_dummies)
names(model_data)[1] = "PM2.5_Hour_MassConc_Calibrated"

# Fit the regression model
ols_model <- lm(PM2.5_Hour_MassConc_Calibrated ~ ., data = model_data)

# Assess overall model fit
# summary(ols_model)

# Perform partial regression analysis
partial_residuals <- residuals(ols_model)

# Fit partial regression models for each neighborhood dummy
neighborhood_partial_models <- lapply(1:ncol(neighborhood_dummies), function(i) {
  lm(partial_residuals ~ neighborhood_dummies[, i])
})

neighborhood = c('Chinatown','Potrero Hill','SoMa','Tenderloin','BVHP')
# Summary of partial regression models
for (i in 1:5) {
  print(neighborhood[i])
  print(summary(neighborhood_partial_models[[i]]))
}
```
### What are the individual contributions of Season to the model?

#### Full Regression Model (OLS)

```{r}
# Model Training with Season Variable
ols_model_season <- lm(PM2.5_Hour_MassConc_Calibrated ~ ., data = train_data[, c("PM2.5_Hour_MassConc_Calibrated", lagged_vars, "Season")])
summary(ols_model_season)
```

```{r}
# Evaluate model performance
predictions_season <- predict(ols_model_season, newdata = test_data)
mape_season <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_season) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100
mape_season
rsquared_season <- summary(ols_model_season)$r.squared
rsquared_season
```

#### Partial Regression (FWL)

```{r}
# Extract lagged variables from the training data
lagged_vars <- grep("^PM2\\.5_Hour_MassConc_Calibrated_lag_", names(train_data), value = TRUE)

# Remove NAs from lagged variables
train_data_no_na <- na.omit(train_data[, c("PM2.5_Hour_MassConc_Calibrated", lagged_vars, "Season")])

# Create dummy variables for the seasons
season_dummies <- model.matrix(~ Season - 1, data = train_data_no_na)

# Move the first column to the end
season_dummies <- cbind(season_dummies[, -1], season_dummies[, 1])

# Combine lagged variables and season dummies
model_data_season <- cbind(train_data_no_na$PM2.5_Hour_MassConc_Calibrated, train_data_no_na[, lagged_vars], season_dummies)
names(model_data_season)[1] <- "PM2.5_Hour_MassConc_Calibrated"

# Fit the regression model with Season variable
ols_model_season_partial <- lm(PM2.5_Hour_MassConc_Calibrated ~ ., data = model_data_season)

# Assess overall model fit
# summary(ols_model_season_partial)

# Perform partial regression analysis for Season variable
partial_residuals_season <- residuals(ols_model_season_partial)

# Fit partial regression models for each season dummy
season_partial_models <- lapply(1:ncol(season_dummies), function(i) {
  lm(partial_residuals_season ~ season_dummies[, i])
})

# Summary of partial regression models for Season variable
season_names <- c("Spring", "Summer", "Fall", "Winter")
for (i in 1:length(season_names)) {
  print(season_names[i])
  print(summary(season_partial_models[[i]]))
}

```


### Do Humidity and Temperature contribute significantly to the model?

```{r}
# Humidity
humidity_ols <- lm(PM2.5_Hour_MassConc_Calibrated ~ ., data = train_data[, c("PM2.5_Hour_MassConc_Calibrated",lagged_vars, "Humidity")])
summary(humidity_ols)

# Temperature
temp_ols <- lm(PM2.5_Hour_MassConc_Calibrated ~ ., data = train_data[, c("PM2.5_Hour_MassConc_Calibrated",lagged_vars, "Temperature")])
summary(temp_ols)

# Humidity and Temperature
temp_humidity_ols <- lm(PM2.5_Hour_MassConc_Calibrated ~ ., data = train_data[, c("PM2.5_Hour_MassConc_Calibrated",lagged_vars, "Humidity","Temperature")])
summary(temp_humidity_ols)
```


```{r}
# Make predictions on the test data set
predictions_humidity <- predict(humidity_ols, newdata = test_data[, c("PM2.5_Hour_MassConc_Calibrated", lagged_vars_test,"Humidity")])
predictions_temp <- predict(temp_ols, newdata = test_data[, c("PM2.5_Hour_MassConc_Calibrated", lagged_vars_test,"Temperature")])
predictions_temp_humidity <- predict(temp_humidity_ols, newdata = test_data[, c("PM2.5_Hour_MassConc_Calibrated", lagged_vars_test,"Humidity","Temperature")])

# Assess performance using MAPE
MAPE_humidity <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_humidity) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100
MAPE_temp <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_temp) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100
MAPE_temp_humidity <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_temp_humidity) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100

# Assess performance using Adjusted R-squared
adjusted_r_squared_humidity <- summary(humidity_ols)$adj.r.squared
adjusted_r_squared_temp <- summary(temp_ols)$adj.r.squared
adjusted_r_squared_temp_humidity <- summary(temp_humidity_ols)$adj.r.squared

# Assess performance using AIC
humidity_aic <- AIC(humidity_ols)
temp_aic <- AIC(temp_ols)
temp_humidity_aic <- AIC(temp_humidity_ols)
summary(data$PM2.5_Hour_MassConc_Calibrated)
```

```{r}
# Create a data frame
model_metrics <- data.frame(
  Model_Includes = c("Neither", "Humidity", "Temperature", "Humidity and Temperature"),
  MAPE = round(c(MAPE, MAPE_humidity, MAPE_temp, MAPE_temp_humidity),6),
  Adj_R2 = round(c(adjusted_r_squared, adjusted_r_squared_humidity, adjusted_r_squared_temp, adjusted_r_squared_temp_humidity),5),
  AIC = round(c(aic, humidity_aic, temp_aic, temp_humidity_aic),2)
)

# Compare model selection criteria
kable(caption= "Test Data Models", model_metrics)
```


```{r}
# Identify individual contributions from humidity and temperature for full model
cat("For every 1 %-point increase in humidity, the predicted PM2.5 value increases by",round(summary(temp_humidity_ols)$coef[optimal_lag_step+2],3),"ug/m^3, holding all else constant.\n")
cat("For every 1 CÂº increase in temperature, the predicted PM2.5 value decreases by",round(-summary(temp_humidity_ols)$coef[optimal_lag_step+3],3),"ug/m^3, holding all else constant.\n")
```

# Model Fitting & Evaluation

## Can we produce a predictive model for PM2.5  with high accuracy?

### OLS 

```{r}
# Run OLS on Training data
ols_model <- lm(PM2.5_Hour_MassConc_Calibrated ~ PM2.5_Hour_MassConc_Calibrated_lag_1 +
            PM2.5_Hour_MassConc_Calibrated_lag_2 + PM2.5_Hour_MassConc_Calibrated_lag_3 + 
            PM2.5_Hour_MassConc_Calibrated_lag_4 + PM2.5_Hour_MassConc_Calibrated_lag_5 +
            PM2.5_Hour_MassConc_Calibrated_lag_6 +
            Humidity + Temperature + factor(Season) + factor(Neighborhood), data = train_data)
summary(ols_model)
```

#### Check Conditions of OLS Model

```{r}
# Check linearity & Homoskedasticity visually using scatter plots
plot(train_data$PM2.5_Hour_MassConc_Calibrated, residuals(ols_model), xlab = "Fitted values", ylab = "Residuals", main="OLS Results")
### Appears Heteroskedastic
```


```{r}
# Independence of Errors with Durbin-Watson Test
durbinWatsonTest(ols_model)
## can't reject null that there is no auto-correlation (good)

# Normality of residuals with  Q-Q plot
qqnorm(residuals(ols_model))
qqline(residuals(ols_model))
### Does not appear normal

# Variance Inflation Factors (VIF)
vif(ols_model)
### High Multicollinearity

# Outliers and Influential Points
## Studentized residuals
plot(ols_model, which = 4)
## Leverage values
plot(ols_model, which = 5)
### Definitely exist outliers and influential points

# Model Fit
## Adjusted R-squared
summary(ols_model)$adj.r.squared
### High Adj R^2 (good)

```

#### Test OLS Model
```{r}
# Make predictions on the test data set
predictions_ols <- predict(ols_model, newdata = test_data)

# Assess performance using MAPE
MAPE_ols <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_ols) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100

# Assess performance using Adjusted R-squared
adj_r2_ols <- summary(ols_model)$adj.r.squared

## Asses performance using AIC
RSS_ols <- sum((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_ols)^2)

# Calculate AIC
n <- nrow(test_data)
aic_ols <- 2 * 16 + n * log(RSS_ols / n)

# Print the evaluation metrics
cat("MAPE: ", MAPE_ols, "% indicates the average deviation of actual values from the model's predictions\n",sep="")
cat("Adjusted R-squared:", adj_r2_ols, "indicates the proportion of variability in the dependent variable explained by the independent variables in the model", "\n")
cat("AIC:",aic_ols)

# plot real vs predicted 
plot(test_data$PM2.5_Hour_MassConc_Calibrated, predictions_ols)
```

### WLS

```{r}
# Calculate weights based on the variance of residuals
residuals <- resid(ols_model)  # Assuming you already have an OLS model
weights <- 1 / residuals^2  # Inverse of squared residuals

# Fit the WLS model
wls_model <- lm(formula = PM2.5_Hour_MassConc_Calibrated ~ PM2.5_Hour_MassConc_Calibrated_lag_1 +
            PM2.5_Hour_MassConc_Calibrated_lag_2 + PM2.5_Hour_MassConc_Calibrated_lag_3 + 
            PM2.5_Hour_MassConc_Calibrated_lag_4 + PM2.5_Hour_MassConc_Calibrated_lag_5 +
            PM2.5_Hour_MassConc_Calibrated_lag_6 +
            Humidity + Temperature + factor(Season) + factor(Neighborhood), data = train_data,
                weights = weights)

# Summary of the WLS model
summary(wls_model)
```

#### Check Conditions of WLS model

```{r}
# Check linearity & Homoskedasticity visually using scatter plots
plot(train_data$PM2.5_Hour_MassConc_Calibrated, residuals(wls_model), xlab = "Fitted values", ylab = "Residuals")
### Appears Heteroskedastic
```


```{r}
# Independence of Errors with Durbin-Watson Test
durbinWatsonTest(wls_model)
## can't reject null that there is no auto-correlation (good)

# Normality of residuals with  Q-Q plot
qqnorm(residuals(wls_model))
qqline(residuals(wls_model))
### Does not appear normal

# Variance Inflation Factors (VIF)
vif(wls_model)
### High Multicollinearity

# Outliers and Influential Points
## Studentized residuals
plot(wls_model, which = 4)
## Leverage values
plot(wls_model, which = 5)
### Definitely exist outliers and influential points

# Model Fit
## Adjusted R-squared
summary(wls_model)$adj.r.squared
### High Adj R^2 (great by design)

```

#### Test WLS model
```{r}
# Make predictions on the test data set
predictions_wls <- predict(wls_model, newdata = test_data)

# Assess performance using MAPE
MAPE_wls <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_wls) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100

# Assess performance using Adjusted R-squared
adj_r2_wls <- summary(wls_model)$adj.r.squared

## Asses performance using AIC
RSS_wls <- sum((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_wls)^2)

# Calculate AIC
aic_wls <- 2 * 16 + n * log(RSS_wls / n)

# aic_wls <- AIC(wls_model)

# Print the evaluation metrics
cat("MAPE: ", MAPE_wls, "% indicates the average deviation of actual values from the model's predictions\n",sep="")
cat("Adjusted R-squared:", adj_r2_wls, "indicates the proportion of variability in the dependent variable explained by the independent variables in the model", "\n")
cat("AIC:",aic_wls)

# plot real vs predicted 
plot(test_data$PM2.5_Hour_MassConc_Calibrated, predictions_wls)
```

### Ridge

```{r}
# Perform Ridge Regression with 10-fold cross-validation
ridge_cv <- lm.ridge(PM2.5_Hour_MassConc_Calibrated ~ PM2.5_Hour_MassConc_Calibrated_lag_1 +
            PM2.5_Hour_MassConc_Calibrated_lag_2 + PM2.5_Hour_MassConc_Calibrated_lag_3 + 
            PM2.5_Hour_MassConc_Calibrated_lag_4 + PM2.5_Hour_MassConc_Calibrated_lag_5 +
            PM2.5_Hour_MassConc_Calibrated_lag_6  +
            Humidity + Temperature + factor(Season) + factor(Neighborhood), data = train_data, lambda = seq(0, 1, 0.01), cv = TRUE, nfolds = 10)

# Find the lambda value that minimizes the cross-validated error
best_lambda_cv <- which.min(ridge_cv$GCV)

# Fit Ridge Regression with the optimal lambda value
ridge_model <- lm.ridge(PM2.5_Hour_MassConc_Calibrated ~ PM2.5_Hour_MassConc_Calibrated_lag_1 +
            PM2.5_Hour_MassConc_Calibrated_lag_2 + PM2.5_Hour_MassConc_Calibrated_lag_3 + 
            PM2.5_Hour_MassConc_Calibrated_lag_4 + PM2.5_Hour_MassConc_Calibrated_lag_5 +
            PM2.5_Hour_MassConc_Calibrated_lag_6  +
            Humidity + Temperature + factor(Season) + factor(Neighborhood), data = train_data, lambda = best_lambda_cv)

# Summarize the Ridge Regression model
summary(ridge_model)
ridge_model$coef
```

#### Test Ridge Regression
```{r}
# Extract coefficients from the ridge model
ridge_coef <- coef(ridge_model)

# Extract predictor variables from the test data
test_subset = test_data[,c("PM2.5_Hour_MassConc_Calibrated_lag_1","PM2.5_Hour_MassConc_Calibrated_lag_2", "PM2.5_Hour_MassConc_Calibrated_lag_3","PM2.5_Hour_MassConc_Calibrated_lag_4","PM2.5_Hour_MassConc_Calibrated_lag_5","PM2.5_Hour_MassConc_Calibrated_lag_6","Humidity","Temperature","Season","Neighborhood")]
# Create dummy variables for Season and Neighborhood
season_dummies <- model.matrix(~ factor(Season) - 1, data = test_data)
neighborhood_dummies <- model.matrix(~ factor(Neighborhood) - 1, data = test_data)
test_subset <- cbind(test_subset[, c("PM2.5_Hour_MassConc_Calibrated_lag_1", "PM2.5_Hour_MassConc_Calibrated_lag_2", "PM2.5_Hour_MassConc_Calibrated_lag_3",  "PM2.5_Hour_MassConc_Calibrated_lag_4", "PM2.5_Hour_MassConc_Calibrated_lag_5", "PM2.5_Hour_MassConc_Calibrated_lag_6", "Humidity","Temperature")], season_dummies, neighborhood_dummies)
test_predictors <-test_subset[,-c(10,14)]
intercept_column <- rep(1, nrow(test_predictors))  # Create a column of 1s
test_predictors_with_intercept <- cbind(intercept_column, test_predictors)

# Manually apply coefficients to the test data
predictions_ridge <- as.matrix(test_predictors_with_intercept) %*% ridge_coef

# Assess performance using MAPE
MAPE_ridge <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_ridge) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100

# Calculate residuals
RSS_ridge <- sum((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_ridge)^2)

# Calculate the total sum of squares (TSS) using the target variable
TSS <- sum((test_data$PM2.5_Hour_MassConc_Calibrated - mean(test_data$PM2.5_Hour_MassConc_Calibrated))^2)

# Get the number of observations (n)
n <- nrow(test_data)

# Calculate Adjusted R-squared
adj_r2_ridge <- 1 - (RSS_ridge / TSS) * (n - 1) / (n - ncol(test_predictors) - 1)

# Calculate AIC
aic_ridge <- 2 * ncol(test_predictors) + n * log(RSS_ridge / n)

# Print the evaluation metrics
cat("MAPE: ", MAPE_ridge, "% indicates the average deviation of actual values from the model's predictions\n",sep="")
cat("Adjusted R-squared:", adj_r2_ridge, "indicates the proportion of variability in the dependent variable explained by the independent variables in the model", "\n")
cat("AIC:",aic_ridge)

# plot real vs predicted 
plot(test_data$PM2.5_Hour_MassConc_Calibrated, predictions_ridge)
```

### Lasso
```{r}
# Extract predictor variables from the training data
train_subset = train_data[,c("PM2.5_Hour_MassConc_Calibrated_lag_1","PM2.5_Hour_MassConc_Calibrated_lag_2", "PM2.5_Hour_MassConc_Calibrated_lag_3","PM2.5_Hour_MassConc_Calibrated_lag_4","PM2.5_Hour_MassConc_Calibrated_lag_5","PM2.5_Hour_MassConc_Calibrated_lag_6","Humidity","Temperature","Season","Neighborhood")]
# Create dummy variables for Season and Neighborhood
season_dummies <- model.matrix(~ factor(Season) - 1, data = train_data)
neighborhood_dummies <- model.matrix(~ factor(Neighborhood) - 1, data = train_data)
train_subset <- cbind(train_subset[, c("PM2.5_Hour_MassConc_Calibrated_lag_1", "PM2.5_Hour_MassConc_Calibrated_lag_2", "PM2.5_Hour_MassConc_Calibrated_lag_3",  "PM2.5_Hour_MassConc_Calibrated_lag_4", "PM2.5_Hour_MassConc_Calibrated_lag_5", "PM2.5_Hour_MassConc_Calibrated_lag_6", "Humidity","Temperature")], season_dummies, neighborhood_dummies)
train_predictors <-train_subset[,-c(10,14)]

# Prepare predictors matrix and target vector
x <- as.matrix(train_predictors)
y <- train_data$PM2.5_Hour_MassConc_Calibrated

# Perform Lasso regression with cross-validation
lasso_cv <- cv.glmnet(x, y, alpha = 1, nfolds = 5)

# Get the optimal lambda value
optimal_lambda <- lasso_cv$lambda.min
```

#### Test Lasso Regression
```{r}
# Extract coefficients from the ridge model
lasso_coef <- coef(lasso_cv, s = "lambda.min")

# Manually apply coefficients to the test data
predictions_lasso <- as.matrix(test_predictors_with_intercept) %*% lasso_coef

# Assess performance using MAPE
MAPE_lasso <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_lasso) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100

# Calculate residuals
RSS_lasso <- sum((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_lasso)^2)

# Calculate Adjusted R-squared
adj_r2_lasso <- 1 - (RSS_lasso / TSS) * (n - 1) / (n - ncol(test_predictors - 1))

# Calculate AIC
aic_lasso <- 2 * ncol(test_predictors) + n * log(RSS_lasso / n)

# Print the evaluation metrics
cat("MAPE: ", MAPE_lasso, "% indicates the average deviation of actual values from the model's predictions\n",sep="")
cat("Adjusted R-squared:", adj_r2_lasso, "indicates the proportion of variability in the dependent variable explained by the independent variables in the model", "\n")
cat("AIC:",aic_lasso)


# plot real vs predicted 
plot(test_data$PM2.5_Hour_MassConc_Calibrated, predictions_lasso)
```


### Weighted Ridge and Lasso Model

```{r}
# Select the optimal lambda using cross-validation
ridge_cv <- cv.glmnet(x, y, alpha = 0, lambda = seq(0, 1, by = 0.01), weights = weights)
lasso_cv <- cv.glmnet(x, y, alpha = 1, lambda = seq(0, 1, by = 0.01), weights = weights)

# Get the optimal lambda value
best_lambda <- lasso_cv$lambda.min

# Fit the final weighted ridge regression model with the optimal lambda
weighted_lasso_model_final <- glmnet(x, y, alpha = 0, lambda = best_lambda, weights = weights)
round(coef(weighted_lasso_model_final),4)
```

#### Test Weighted Ridge Model and Weighted Lasso Model

```{r}
# Extract coefficients from the ridge model
weighted_ridge_coef <- coef(ridge_cv, s = "lambda.min")

# Extract coefficients from the ridge model
weighted_lasso_coef <- coef(lasso_cv, s = "lambda.min")

# Manually apply coefficients to the test data
predictions_weighted_ridge <- as.matrix(test_predictors_with_intercept) %*% weighted_ridge_coef
predictions_weighted_lasso <- as.matrix(test_predictors_with_intercept) %*% weighted_lasso_coef

# Assess performance using MAPE
MAPE_weighted_ridge <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_weighted_ridge) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100
MAPE_weighted_lasso <- mean(abs((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_weighted_lasso) / test_data$PM2.5_Hour_MassConc_Calibrated)) * 100

# Calculate residuals
RSS_weighted_ridge <- sum((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_weighted_ridge)^2)
RSS_weighted_lasso <- sum((test_data$PM2.5_Hour_MassConc_Calibrated - predictions_weighted_lasso)^2)

# Calculate Adjusted R-squared
adj_r2_weighted_ridge <- 1 - (RSS_weighted_ridge / TSS) * (n - 1) / (n - ncol(test_predictors - 1))
adj_r2_weighted_lasso <- 1 - (RSS_weighted_lasso / TSS) * (n - 1) / (n - ncol(test_predictors - 1))

# Calculate AIC
aic_weighted_ridge <- 2 * ncol(test_predictors) + n * log(RSS_weighted_ridge / n)
aic_weighted_lasso <- 2 * ncol(test_predictors) + n * log(RSS_weighted_lasso / n)

plot(predictions_weighted_lasso, test_data$PM2.5_Hour_MassConc_Calibrated, xlab="fitted", ylab="actual", main="Weighted Lasso Model")
```



### Evaluate Models using Selection Criteria

```{r}
# Create a data frame
model_metrics <- data.frame(
  Model = c("OLS", "WLS", "Ridge", "Lasso","Weighted Ridge","Weighted Lasso"),
  MAPE = round(c(MAPE_ols, MAPE_wls, MAPE_ridge, MAPE_lasso, MAPE_weighted_ridge, MAPE_weighted_lasso),2),
  Adj_R_2 = round(c(adj_r2_ols, adj_r2_wls, adj_r2_ridge, adj_r2_lasso, adj_r2_weighted_ridge, adj_r2_weighted_lasso),4),
  AIC = round(c(aic_ols, aic_wls, aic_ridge, aic_lasso, aic_weighted_ridge, aic_weighted_lasso),0)
)

# Compare model selection criteria
kable(model_metrics)
```


# Sensitivity Analysis

## How do anomalously high PM2.5 values affect the model?

### Identify High Outliers

#### Identify Outliers in the OLS Model using Cook's Distance

```{r}
# Calculate Predicted Values form the OLS Model
fitted_values = predict(ols_model, newdata = train_data)

# Calculate leverage scores
leverage <- hatvalues(ols_model)

# Calculate the residuals
residuals <- lag_data$PM2.5_Hour_MassConc_Calibrated - fitted_values

# Calculate the number of observations
n_obs <- length(residuals)

# Calculate the number of predictors (including the intercept)
n_predictors <- ncol(test_predictors_with_intercept)

# Calculate the degrees of freedom
df_residuals <- n_obs - n_predictors

# Calculate Cook's distance
cooks_distance <- leverage * (residuals^2 / (df_residuals * sigma(ols_model)^2))

# Set a threshold
threshold <- quantile(cooks_distance, 0.9)

# Identify outliers based on Cook's distance
outliers <- cooks_distance > threshold

# Extract rows corresponding to outliers from the original data
outlier_data_cooks <- train_data[outliers, ]

# Print the number of outliers
print(nrow(outlier_data_cooks))
head(outlier_data_cooks)
```

#### Identify outliers using top 1% contributors to the OLS Coefficient

##### Use Theorem 11.2 to Calculate the Difference between the Full OLS estimator and the Leave one Out OLS estimator for each outlier

```{r}
# Calculate (1 - h_ii)^(-1) for each observation
inv_one_minus_hii <- 1 / (1 - leverage)

# Compute the contribution of each observation to coefficient estimates
X <- model.matrix(ols_model)  # Design matrix
XtX_inv <- solve(t(X) %*% X)  # Inverse of X'X
coefficients <- coef(ols_model)  # Coefficients
residuals <- residuals(ols_model)  # Residuals


contributions <- numeric(length = nrow(train_data))

# Iterate over each observation
for (i in 1:length(contributions)) {
  # Extract the design matrix row for observation i
  xi <- X[i, , drop = FALSE]
  
  # Calculate x_i * epsilon_i
  xi_eps_i <- xi * residuals[i]
  
  # Calculate the contribution of observation i to coefficient estimates
  contribution <- inv_one_minus_hii[i] * xi_eps_i %*% XtX_inv
  
  # Store the contribution
  contributions[i] <- sum(contribution)
}
```

```{r}
threshold_2 <- quantile(contributions, .9)
outliers_2 <- contributions > threshold_2
outlier_data_loo <- train_data[outliers_2, ]
nrow(outlier_data_loo)
```

#### Compare Outliers

```{r}
# How many outliers in common out of 4477
intersect(outlier_data_cooks, outlier_data_loo) # 762

# Convert "Date" column to Date type if it's not already in Date format
outlier_data_cooks$Date <- as.Date(outlier_data_cooks$Datetime)
outlier_data_loo$Date <- as.Date(outlier_data_loo$Datetime)

# Count the number of occurrences of each date
count_date <- table(outlier_data_cooks$Date)
count_date_2 <- table(outlier_data_loo$Date)

# Create data frames for plotting
plot_data <- data.frame(Date = as.Date(names(count_date)), Count = as.numeric(count_date))
plot_data_2 <- data.frame(Date = as.Date(names(count_date_2)), Count = as.numeric(count_date_2))

# Plot
ggplot() +
  geom_line(data = plot_data, aes(x = Date, y = Count, color = "Cook's Distance"), size =.3, alpha = .5) +
  geom_line(data = plot_data_2, aes(x = Date, y = Count, color = "LOO Contributions"), size=.3, alpha = .5) +
  labs(title = "Comparison of Outlier Dates", x = "Date", y = "Number of Outliers") +
  scale_color_manual(values = c("Cook's Distance" = "blue", "LOO Contributions" = "red")) +
  theme_minimal()

```


### Test which set of outliers to exclude produces a better performing OLS model

```{r}
# Define a function to return coefficients using OLS
get_ols_coefficients <- function(x, y) {
  # Fit the OLS model
  df = cbind(y,x)
  ols_model <- lm(y ~ ., data=df)
  
  # Get coefficients
  ols_coef <- coef(ols_model)
  
  return(ols_coef)
}

# Function to obtain coefficients by excluding all outliers for OLS
exclude_all_outliers_ols <- function(train_data, outliers_to_exclude) {
  # Exclude outliers from the dataset
  train_data_clean <- train_data[!train_data$Datetime %in% outliers_to_exclude$Datetime, ]
  
  # Prepare predictor matrix and target vector
  x_subset <- prepare_data(train_data_clean)$x
  y_subset <- prepare_data(train_data_clean)$y
  
  # Get coefficients for the cleaned data
  coefficients <- get_ols_coefficients(x_subset, y_subset)
  
  return(coefficients)
}

# Function to prepare data for ridge regression
prepare_data <- function(lag_data_subset) {
  # Prepare predictor matrix x
  data_subset <- lag_data_subset[, c("PM2.5_Hour_MassConc_Calibrated_lag_1", 
                                     "PM2.5_Hour_MassConc_Calibrated_lag_2",
                                     "PM2.5_Hour_MassConc_Calibrated_lag_3",
                                     "PM2.5_Hour_MassConc_Calibrated_lag_4",
                                     "PM2.5_Hour_MassConc_Calibrated_lag_5",
                                     "PM2.5_Hour_MassConc_Calibrated_lag_6",
                                     "Humidity", "Temperature", "Season", "Neighborhood")]
  
  # Create dummy variables for Season and Neighborhood
  season_dummies <- model.matrix(~ factor(lag_data_subset$Season) - 1, data = lag_data_subset)
  neighborhood_dummies <- model.matrix(~ factor(lag_data_subset$Neighborhood) - 1, data = lag_data_subset)
  data_subset <- cbind(data_subset[, c("PM2.5_Hour_MassConc_Calibrated_lag_1", 
                                        "PM2.5_Hour_MassConc_Calibrated_lag_2",
                                        "PM2.5_Hour_MassConc_Calibrated_lag_3",
                                        "PM2.5_Hour_MassConc_Calibrated_lag_4",
                                        "PM2.5_Hour_MassConc_Calibrated_lag_5",
                                        "PM2.5_Hour_MassConc_Calibrated_lag_6",
                                        "Humidity", "Temperature")], 
                       season_dummies[,-c(1)], neighborhood_dummies[,-c(1)])
  
  # Prepare target vector y
  y <- lag_data_subset$PM2.5_Hour_MassConc_Calibrated
  
  # Return predictor matrix x and target vector y
  return(list(x = data_subset, y = y))
}
```

```{r}
# Run Weighted Ridge Model Excluding Outliers
ols_coef_cooks <- exclude_all_outliers_ols(train_data, outlier_data_cooks) 
ols_coef_loo <- exclude_all_outliers_ols(train_data, outlier_data_loo) 
``` 

```{r}
prepare_test_data <- function(test_data, outliers_to_exclude) {
  # Extract predictor variables from the test data
  test_subset <- test_data[, c("PM2.5_Hour_MassConc_Calibrated_lag_1", 
                               "PM2.5_Hour_MassConc_Calibrated_lag_2",
                               "PM2.5_Hour_MassConc_Calibrated_lag_3",
                               "PM2.5_Hour_MassConc_Calibrated_lag_4",
                               "PM2.5_Hour_MassConc_Calibrated_lag_5",
                               "PM2.5_Hour_MassConc_Calibrated_lag_6",
                               "Humidity", "Temperature", "Season", "Neighborhood")]
  
  # Create dummy variables for Season and Neighborhood
  season_dummies <- model.matrix(~ factor(test_data$Season) - 1, data = test_data)
  neighborhood_dummies <- model.matrix(~ factor(test_data$Neighborhood) - 1, data = test_data)
  test_subset <- cbind(test_subset[, c("PM2.5_Hour_MassConc_Calibrated_lag_1", 
                                        "PM2.5_Hour_MassConc_Calibrated_lag_2",
                                        "PM2.5_Hour_MassConc_Calibrated_lag_3",
                                        "PM2.5_Hour_MassConc_Calibrated_lag_4",
                                        "PM2.5_Hour_MassConc_Calibrated_lag_5",
                                        "PM2.5_Hour_MassConc_Calibrated_lag_6",
                                        "Humidity", "Temperature")], 
                       season_dummies, neighborhood_dummies)
  
  # Prepare predictor matrix with intercept
  test_predictors <- test_subset[, -c(10, 14)]  # Exclude the last columns (Season and Neighborhood)
  intercept_column <- rep(1, nrow(test_predictors))  # Create a column of 1s
  test_predictors_with_intercept <- cbind(intercept_column, test_predictors)
  
  # Exclude outliers from the test data
  test_data_clean <- test_data[!test_data$Datetime %in% outliers_to_exclude$Datetime, ]
  
  return(list(test_data = test_data_clean, test_predictors = test_predictors_with_intercept))
}
```


```{r}
# Set up test data for both sets of outliers
cooks_test <- prepare_test_data(test_data, outlier_data_cooks)$test_data
loo_test <- prepare_test_data(test_data, outlier_data_loo)$test_data
cooks_predictors <- prepare_test_data(cooks_test, outlier_data_cooks)$test_predictors
loo_predictors <- prepare_test_data(loo_test, outlier_data_loo)$test_predictors
n <- nrow(cooks_test)

# Manually apply coefficients to the test data
predictions_cooks <- as.matrix(cooks_predictors) %*%ols_coef_cooks
predictions_loo <- as.matrix(loo_predictors) %*% ols_coef_loo

# Assess performance using MAPE for Cook's distance
MAPE_cooks <- mean(abs((cooks_test$PM2.5_Hour_MassConc_Calibrated - predictions_cooks) / cooks_test$PM2.5_Hour_MassConc_Calibrated)) * 100

# Assess performance using MAPE for LOO
MAPE_loo <- mean(abs((loo_test$PM2.5_Hour_MassConc_Calibrated - predictions_loo) / loo_test$PM2.5_Hour_MassConc_Calibrated)) * 100

# Calculate residuals for Cook's distance
RSS_cooks <- sum((cooks_test$PM2.5_Hour_MassConc_Calibrated - predictions_cooks)^2)
TSS_cooks <- sum((cooks_test$PM2.5_Hour_MassConc_Calibrated - mean(cooks_test$PM2.5_Hour_MassConc_Calibrated))^2)

# Calculate residuals for LOO
RSS_loo <- sum((loo_test$PM2.5_Hour_MassConc_Calibrated - predictions_loo)^2)
TSS_loo <- sum((loo_test$PM2.5_Hour_MassConc_Calibrated - mean(loo_test$PM2.5_Hour_MassConc_Calibrated))^2)

# Calculate Adjusted R-squared for Cook's distance
adj_r2_cooks <- 1 - (RSS_cooks / TSS_cooks) * (n - 1) / (n - ncol(cooks_predictors) - 1)

# Calculate Adjusted R-squared for LOO
adj_r2_loo <- 1 - (RSS_loo / TSS_loo) * (n - 1) / (n - ncol(loo_predictors) - 1)

# Calculate AIC for Cook's distance
aic_cooks <- 2 * ncol(test_predictors) + n * log(RSS_cooks / n)

# Calculate AIC for LOO
aic_loo <- 2 * ncol(test_predictors) + n * log(RSS_loo / n)

# Print performance metrics for Cook's distance
cat("Performance Metrics for Cook's Distance:\n")
cat("MAPE: ", MAPE_cooks, "%\n")
cat("Adjusted R-squared: ", adj_r2_cooks, "\n")
cat("AIC: ", aic_cooks, "\n")

# Print performance metrics for LOO
cat("\nPerformance Metrics for LOO:\n")
cat("MAPE: ", MAPE_loo, "%\n")
cat("Adjusted R-squared: ", adj_r2_loo, "\n")
cat("AIC: ", aic_loo, "\n")
## Seems like Cook's Outliers are better to exclude
```

# "Best" Predictive Model

## Final Evaluation of Model Performance

```{r}
# Create a data frame
total_model_metrics <- data.frame(
  Model = c("OLS", "WLS", "Ridge", "Lasso","Weighted Ridge","Weighted Lasso","OLS w/o Cook's Outliers", "OLS w/o LOO Outliers"),
  MAPE = round(c(MAPE_ols, MAPE_wls, MAPE_ridge, MAPE_lasso, MAPE_weighted_ridge, MAPE_weighted_lasso, MAPE_cooks, MAPE_loo),3),
  Adj_R2 = round(c(adj_r2_ols, adj_r2_wls, adj_r2_ridge, adj_r2_lasso, adj_r2_weighted_ridge, adj_r2_weighted_lasso, adj_r2_cooks, adj_r2_loo),4),
  AIC = round(c(aic_ols, aic_wls, aic_ridge, aic_lasso, aic_weighted_ridge, aic_weighted_lasso, aic_cooks, aic_loo),0)
)

# Compare model selection criteria
kable(total_model_metrics)
```

## Winning Model

```{r}
# Exclude outliers from the dataset
train_data_clean <- train_data[!train_data$Datetime %in% outlier_data_loo$Datetime, ]
  
# Prepare predictor matrix and target vector
x_subset <- prepare_data(train_data_clean)$x
y_subset <- prepare_data(train_data_clean)$y
  
# Compute OLS Model on subsetted data
df = cbind(y_subset,x_subset)
final_ols_model <- lm(y_subset ~ ., data=df)
summary(final_ols_model)
```

\begin{align*}
PM_{2.5_{t, i}} = & - \text{2.43} + \text{0.75}  PM_{2.5_{t-1, i}} + \text{0.15}  PM_{2.5_{t-2}, i}  + \text{0.03}  PM_{2.5_{t-3, i}} + \text{0.04}  PM_{2.5_{t-4, i}} + \text{0.01}  PM_{2.5_{t-5, i}}\\
&    + \text{0.01}  PM_{2.5_{t-6}, i} + \text{0.03}  Humidity_{t, i} + \text{0.08}  Temperature_{t, i} - \text{0.22}  Winter_{t, i} - \text{0.43}  Chinatown_{t, i} \\
& - \text{0.28}  Potrero\ Hill_{t, i} - \text{0.29}  SoMa_{t, i} - \text{0.34}  Tenderloin_{t, i} + \epsilon_{t, i}
\end{align*}



```{r}
# Predicted vs Actual Plot
# Predicted vs Actual Plot with closed and small dots
predicted <- predict(final_ols_model)
actual <- train_data_clean$PM2.5_Hour_MassConc_Calibrated
plot(predicted, actual, xlab = "fitted PM2.5", ylab = "actual PM2.5", main = "OLS Model Excluding Outliers",col = rgb(0, 0, 1, 0.3), pch = 20, cex = 0.8)
abline(0, 1) 
```
```{r}
# Prepare predictor matrix and target vector
lagged_data <- generate_lagged_values(optimal_lag_step)$lag_data
lag_data_clean <- lagged_data[!lagged_data$Datetime %in% outlier_data_loo$Datetime, ]

x_subset <- prepare_data(lag_data_clean)$x
y_subset <- prepare_data(lag_data_clean)$y
  
# Compute OLS Model on subsetted data
df <- cbind(y_subset, x_subset)
final_ols_model <- lm(y_subset ~ ., data = df)

# Assuming final_ols_model is your fitted OLS model
predicted <- predict(final_ols_model)
actual <- lag_data_clean$PM2.5_Hour_MassConc_Calibrated

# Extract Datetime, neighborhood, and Device_Name data
datetime <- lag_data_clean$Datetime
neighborhood <- lag_data_clean$Neighborhood
device_name <- lag_data_clean$Device_Name

# Combine actual, predicted, datetime, neighborhood, and Device_Name values into a data frame
plot_data <- data.frame(Datetime = datetime, Neighborhood = neighborhood, Device_Name = device_name, Actual = actual, Predicted = predicted)
nrow(plot_data)
subset = plot_data[plot_data$Datetime > "2022-06-14 21:00:00 PDT" & plot_data$Datetime < "2022-06-30 21:00:00 PDT",]
1-mean(abs(round(subset$Actual,5)-round(subset$Predicted,5))/round(subset$Actual,5))
#9-10 2022
```


```{r}
# Create a subset for the last 100 values
sub <- plot_data[1:200,]
sub<-sub[seq(1, nrow(plot_data), by = 2), ]

# Create the plot
ggplot(sub, aes(x = Datetime)) +
  geom_line(aes(y = Actual, color = "Actual"), alpha = 0.5, size = .2) +
  geom_line(aes(y = Predicted, color = "Predicted"), alpha = 0.5, size = .2) +
  labs(x = "Datetime", y = "PM2.5", title = "Actual vs Predicted PM2.5 Time Series") +
  scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank())
```


```{r}
# Combine actual and predicted values into a single column
tableau_data <- data.frame(
  Datetime = datetime,
  Neighborhood = neighborhood,
  Device_Name = device_name,
  PM2.5 = c(actual, predicted),
  Type = rep(c("Actual", "Predicted"), each = length(actual))
)

# Save data to csv
# write.csv(tableau_data, "forecasting.csv")

```


